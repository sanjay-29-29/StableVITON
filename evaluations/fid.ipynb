{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3Dataset(Dataset):\n",
    "    def __init__(self, images_path, device='cuda'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.device = device\n",
    "\n",
    "        self.image_files = os.listdir(images_path)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(299),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(osp.join(self.images_path, self.image_files[idx]))\n",
    "        image_tensor = self.transform(image).to(self.device)\n",
    "\n",
    "        return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jun/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception v3 model loaded\n"
     ]
    }
   ],
   "source": [
    "inception_v3 = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', weights='IMAGENET1K_V1')\n",
    "\n",
    "inception_v3.to('cuda')\n",
    "inception_v3.eval()\n",
    "\n",
    "print('inception v3 model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace last two layers of inception_v3\n",
    "class ID(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ID, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "inception_v3.dropout = ID()\n",
    "inception_v3.fc = ID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of output images: 2032\n",
      "# of gt images: 2032\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../output/2024_02_22_17:33:26_pair/'\n",
    "gt_dir = '../DATA/VITON-HD/test/image/'\n",
    "\n",
    "output_dataset = InceptionV3Dataset(output_dir)\n",
    "gt_dataset = InceptionV3Dataset(gt_dir)\n",
    "\n",
    "print('# of output images:', len(output_dataset))\n",
    "print('# of gt images:', len(gt_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataloader = DataLoader(dataset=output_dataset, batch_size=512)\n",
    "gt_dataloader = DataLoader(dataset=gt_dataset, batch_size=512)\n",
    "\n",
    "output_activation = []\n",
    "gt_activation = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in output_dataloader:\n",
    "        act = inception_v3(batch).detach().cpu().numpy()\n",
    "        output_activation.append(act)\n",
    "    for batch in gt_dataloader:\n",
    "        act = inception_v3(batch).detach().cpu().numpy()\n",
    "        gt_activation.append(act)\n",
    "\n",
    "output_activation = np.vstack(output_activation)\n",
    "gt_activation = np.vstack(gt_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/mseitzer/pytorch-fid\n",
    "\n",
    "# define frechet_distance\n",
    "def frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    # Product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # Numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1)\n",
    "            + np.trace(sigma2) - 2 * tr_covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FID]\n",
      "7.177\n"
     ]
    }
   ],
   "source": [
    "mu1 = output_activation.mean(axis=0)\n",
    "sigma1 = np.cov(output_activation, rowvar=False)\n",
    "\n",
    "mu2 = gt_activation.mean(axis=0)\n",
    "sigma2 = np.cov(gt_activation, rowvar=False)\n",
    "\n",
    "FID = frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "print('[FID]')\n",
    "print('%.3f' % FID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StableVITON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
